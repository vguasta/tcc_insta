{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c216a87c",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bff01e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, shutil, random, time\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from InstagramAPI import InstagramAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5d6962",
   "metadata": {},
   "source": [
    "# 0. Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "30f66ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATE_BEGIN                : 1609470000.0\n",
      "PATH_BASE                 : D:\\IC\n",
      "PATH_BASE_DATA            : D:\\IC\\data\n",
      "PATH_1_CREATING_DATASET   : D:\\IC\\data\\1-Creating_Dataset\n",
      "PATH_FIRST_DATASET        : D:\\IC\\data\\1-Creating_Dataset\\Dataset\n",
      "PATH_FIRST_DATASET_TYPE   : D:\\IC\\data\\1-Creating_Dataset\\Dataset\\guastafriends\n",
      "PATH_2_PREPARING_DATASET  : D:\\IC\\data\\2-Preparing_Dataset\n",
      "PATH_CLEAN_DATASET        : D:\\IC\\data\\2-Preparing_Dataset\\Clean_Dataset\n",
      "PATH_CLEAN_DATASET_TYPE   : D:\\IC\\data\\2-Preparing_Dataset\\Clean_Dataset\\guastafriends\n",
      "PATH_3_PROCESSING_DATASET : D:\\IC\\data\\3-Processing_Dataset\n",
      "PATH_4_CLASSIFYING_DATASET: D:\\IC\\data\\4-Classifying_Dataset\n"
     ]
    }
   ],
   "source": [
    "TYPE = \"guastafriends\"\n",
    "\n",
    "DATE_BEGIN = datetime(2021,1,1,0,0).timestamp()\n",
    "\n",
    "PATH_BASE                  = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "PATH_BASE_DATA             = os.path.join(PATH_BASE, \"data\")\n",
    "PATH_1_CREATING_DATASET    = os.path.join(PATH_BASE_DATA, \"1-Creating_Dataset\")\n",
    "PATH_FIRST_DATASET         = os.path.join(PATH_1_CREATING_DATASET, \"Dataset\")\n",
    "PATH_FIRST_DATASET_TYPE    = os.path.join(PATH_FIRST_DATASET, TYPE)\n",
    "PATH_2_PREPARING_DATASET   = os.path.join(PATH_BASE_DATA, \"2-Preparing_Dataset\")\n",
    "PATH_CLEAN_DATASET         = os.path.join(PATH_2_PREPARING_DATASET, \"Clean_Dataset\")\n",
    "PATH_CLEAN_DATASET_TYPE    = os.path.join(PATH_CLEAN_DATASET, TYPE)\n",
    "PATH_3_PROCESSING_DATASET  = os.path.join(PATH_BASE_DATA, \"3-Processing_Dataset\")\n",
    "PATH_4_CLASSIFYING_DATASET = os.path.join(PATH_BASE_DATA, \"4-Classifying_Dataset\")\n",
    "\n",
    "RAIO_FOLLOWERS = 3\n",
    "RAIO_LIKES = 95\n",
    "\n",
    "BATCH_LABEL_COUNTER = 7500\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "CV = 10\n",
    "\n",
    "print(f\"DATE_BEGIN                : {DATE_BEGIN}\")\n",
    "print(f\"PATH_BASE                 : {PATH_BASE}\")\n",
    "print(f\"PATH_BASE_DATA            : {PATH_BASE_DATA}\")\n",
    "print(f\"PATH_1_CREATING_DATASET   : {PATH_1_CREATING_DATASET}\")\n",
    "print(f\"PATH_FIRST_DATASET        : {PATH_FIRST_DATASET}\")\n",
    "print(f\"PATH_FIRST_DATASET_TYPE   : {PATH_FIRST_DATASET_TYPE}\")\n",
    "print(f\"PATH_2_PREPARING_DATASET  : {PATH_2_PREPARING_DATASET}\")\n",
    "print(f\"PATH_CLEAN_DATASET        : {PATH_CLEAN_DATASET}\")\n",
    "print(f\"PATH_CLEAN_DATASET_TYPE   : {PATH_CLEAN_DATASET_TYPE}\")\n",
    "print(f\"PATH_3_PROCESSING_DATASET : {PATH_3_PROCESSING_DATASET}\")\n",
    "print(f\"PATH_4_CLASSIFYING_DATASET: {PATH_4_CLASSIFYING_DATASET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07557f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_print(data):\n",
    "    print(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {data}\", flush=True)\n",
    "\n",
    "def error_log(acc, log_type, e):\n",
    "    log_print(f\"Failed to process {acc} account: {str(e)}\")\n",
    "    log_print(f\"Appending to file {TYPE}_users_error.log\")\n",
    "    error_file = open(os.path.join(PATH_1_CREATING_DATASET, f\"{TYPE}_users_error.log\"), \"a\")\n",
    "    error_file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')} - {log_type} - {acc} - {str(e)}\")\n",
    "    error_file.write(\"\\n\")\n",
    "    error_file.close()\n",
    "    print(\"**********************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa21a0e",
   "metadata": {},
   "source": [
    "# 1. Creating Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db82974",
   "metadata": {},
   "source": [
    "## 1.1. Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53978827",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(PATH_1_CREATING_DATASET, \"logins.json\")) as json_file:\n",
    "     file_logins = json.load(json_file)\n",
    "\n",
    "def get_login(id_login=0, logins=file_logins[\"Logins\"]):\n",
    "    api = None\n",
    "    logged = False\n",
    "    while not logged:      \n",
    "        log_print(\"Trying login in account: \" + logins[id_login][\"username\"])\n",
    "        api = InstagramAPI(logins[id_login][\"username\"], logins[id_login][\"password\"])\n",
    "        logged = api.login()\n",
    "        if not logged:\n",
    "            id_login += 1\n",
    "            if id_login >= len(logins):\n",
    "                id_login = 0\n",
    "            time.sleep(3)\n",
    "    return (api, id_login)\n",
    "        \n",
    "def get_accounts():\n",
    "    file_accounts = open(os.path.join(PATH_1_CREATING_DATASET, f\"{TYPE}_users.txt\"), 'r')\n",
    "    if not os.path.exists(os.path.join(PATH_1_CREATING_DATASET, f\"{TYPE}_users.bkp\")):\n",
    "        shutil.copyfile(os.path.join(PATH_1_CREATING_DATASET, f\"{TYPE}_users.txt\"), os.path.join(PATH_1_CREATING_DATASET, f\"{TYPE}_users.bkp\"))\n",
    "    list_accounts = file_accounts.readlines()\n",
    "    file_accounts.close()\n",
    "    return list_accounts\n",
    "\n",
    "def create_folder_acc(acc):\n",
    "    if not os.path.exists(os.path.join(PATH_FIRST_DATASET_TYPE, acc)):\n",
    "        log_print(f\"Creating folder {acc}\")\n",
    "        if not os.path.exists(PATH_FIRST_DATASET_TYPE):\n",
    "            os.mkdir(PATH_FIRST_DATASET_TYPE)\n",
    "        os.mkdir(os.path.join(PATH_FIRST_DATASET_TYPE, acc))\n",
    "        log_print(f\"Folder {acc} created\")\n",
    "\n",
    "def create_file_user_info(user):\n",
    "    log_print(\"Creating file user_info\")\n",
    "    user[\"collected_at\"] = datetime.timestamp(datetime.now())\n",
    "    with open(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"user_info.json\"), 'w+', encoding=\"utf-8\") as json_file:\n",
    "        json.dump(user, json_file, indent=4, ensure_ascii=False)\n",
    "    log_print(\"File user_info created\")\n",
    "\n",
    "def get_user_feed(api, id_login, user, next_max_id=None):\n",
    "    get_user_feed = False\n",
    "    while not get_user_feed:\n",
    "        if next_max_id == None:\n",
    "            api.getUserFeed(user['pk'], minTimestamp=int(DATE_BEGIN))\n",
    "        else:\n",
    "            api.getUserFeed(user['pk'], maxid=next_max_id, minTimestamp=int(DATE_BEGIN))\n",
    "        if api.LastResponse.status_code == 429:\n",
    "            (api, id_login) = get_login(id_login=id_login)\n",
    "        else:\n",
    "            get_user_feed = True\n",
    "    return (api, id_login)\n",
    "\n",
    "def create_file_user_posts(api, id_login, user):\n",
    "    log_print(\"Creating file user_posts\")\n",
    "    (api, id_login) = get_user_feed(api, id_login, user)\n",
    "    \n",
    "    if api.LastResponse.status_code == 400:\n",
    "        raise Exception(api.LastJson)\n",
    "        \n",
    "    posts = api.LastJson\n",
    "\n",
    "    while (posts[\"more_available\"]):\n",
    "        time.sleep(round(random.uniform(1,3), 1))\n",
    "        aux_bool = False\n",
    "        (api, id_login) = get_user_feed(api, id_login, user, posts[\"next_max_id\"])\n",
    "\n",
    "        posts[\"items\"].extend(api.LastJson[\"items\"])\n",
    "        posts[\"num_results\"] += api.LastJson[\"num_results\"]\n",
    "        posts[\"more_available\"] =  api.LastJson[\"more_available\"]\n",
    "        if posts[\"more_available\"]:\n",
    "            posts[\"next_max_id\"] = api.LastJson[\"next_max_id\"]\n",
    "        else:\n",
    "            del posts['next_max_id']\n",
    "        posts[\"auto_load_more_enabled\"] = api.LastJson[\"auto_load_more_enabled\"]\n",
    "        posts[\"status\"] = api.LastJson[\"status\"]\n",
    "    posts[\"collected_at\"] = datetime.timestamp(datetime.now())\n",
    "    with open(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"user_posts.json\"), 'w+', encoding=\"utf-8\") as json_file:\n",
    "        json.dump(posts, json_file, indent=4, ensure_ascii=False)\n",
    "    log_print(\"File user_posts created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "908fbc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:05:03 - Trying login in account: albert.collector99\n",
      "Request return 405 error!\n",
      "{'message': '', 'status': 'fail'}\n",
      "Request return 404 error!\n",
      "Login success!\n",
      "\n",
      "2021-06-20 21:05:06 - Type: guastafriends\n",
      "2021-06-20 21:05:06 - Starting...\n",
      "\n",
      "2021-06-20 21:05:06 - Searching account _guasta\n",
      "2021-06-20 21:05:08 - Creating file user_info\n",
      "2021-06-20 21:05:08 - File user_info created\n",
      "2021-06-20 21:05:08 - Creating file user_posts\n",
      "2021-06-20 21:05:08 - File user_posts created\n",
      "2021-06-20 21:05:08 - Account _guasta successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:08 - Searching account joao.squinelato\n",
      "2021-06-20 21:05:10 - Creating file user_info\n",
      "2021-06-20 21:05:10 - File user_info created\n",
      "2021-06-20 21:05:10 - Creating file user_posts\n",
      "2021-06-20 21:05:11 - File user_posts created\n",
      "2021-06-20 21:05:11 - Account joao.squinelato successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:11 - Searching account analiviafr\n",
      "2021-06-20 21:05:13 - Creating file user_info\n",
      "2021-06-20 21:05:13 - File user_info created\n",
      "2021-06-20 21:05:13 - Creating file user_posts\n",
      "2021-06-20 21:05:13 - File user_posts created\n",
      "2021-06-20 21:05:13 - Account analiviafr successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:13 - Searching account nmttlbch\n",
      "2021-06-20 21:05:15 - Creating file user_info\n",
      "2021-06-20 21:05:15 - File user_info created\n",
      "2021-06-20 21:05:15 - Creating file user_posts\n",
      "Request return 400 error!\n",
      "{'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "2021-06-20 21:05:15 - Failed to process nmttlbch account: {'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "\n",
      "2021-06-20 21:05:15 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:15 - Searching account stheflacerda\n",
      "2021-06-20 21:05:16 - Creating file user_info\n",
      "2021-06-20 21:05:16 - File user_info created\n",
      "2021-06-20 21:05:16 - Creating file user_posts\n",
      "Request return 400 error!\n",
      "{'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "2021-06-20 21:05:17 - Failed to process stheflacerda account: {'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "\n",
      "2021-06-20 21:05:17 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:17 - Searching account thayfcruz\n",
      "2021-06-20 21:05:18 - Creating file user_info\n",
      "2021-06-20 21:05:18 - File user_info created\n",
      "2021-06-20 21:05:18 - Creating file user_posts\n",
      "2021-06-20 21:05:18 - File user_posts created\n",
      "2021-06-20 21:05:18 - Account thayfcruz successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:18 - Searching account mariavuzum\n",
      "2021-06-20 21:05:20 - Creating file user_info\n",
      "2021-06-20 21:05:20 - File user_info created\n",
      "2021-06-20 21:05:20 - Creating file user_posts\n",
      "2021-06-20 21:05:20 - File user_posts created\n",
      "2021-06-20 21:05:20 - Account mariavuzum successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:20 - Searching account matheuserrera\n",
      "2021-06-20 21:05:21 - Creating file user_info\n",
      "2021-06-20 21:05:21 - File user_info created\n",
      "2021-06-20 21:05:21 - Creating file user_posts\n",
      "2021-06-20 21:05:21 - File user_posts created\n",
      "2021-06-20 21:05:21 - Account matheuserrera successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:05:21 - Searching account marcos.p.andrade\n",
      "2021-06-20 21:05:22 - Creating file user_info\n",
      "2021-06-20 21:05:22 - File user_info created\n",
      "2021-06-20 21:05:22 - Creating file user_posts\n",
      "Request return 400 error!\n",
      "{'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "2021-06-20 21:05:23 - Failed to process marcos.p.andrade account: {'message': 'Not authorized to view user', 'status': 'fail'}\n",
      "\n",
      "2021-06-20 21:05:23 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(api, id_login) = get_login()\n",
    "\n",
    "log_print(\"Type: \" + TYPE)\n",
    "log_print(\"Starting...\\n\")\n",
    "\n",
    "list_accounts = get_accounts()\n",
    "for acc in list_accounts:\n",
    "    acc = str(acc).strip()\n",
    "\n",
    "    try:\n",
    "        log_print(f\"Searching account {acc}\")\n",
    "        time.sleep(round(random.uniform(0.5, 1.5), 1))\n",
    "        api.searchUsername(acc)\n",
    "        if api.LastResponse.status_code == 200:\n",
    "            imgs_user = {}\n",
    "            imgs_user[\"user\"] = acc\n",
    "            imgs_user[\"downloaded\"] = 0\n",
    "            \n",
    "            create_folder_acc(acc)\n",
    "            user = api.LastJson[\"user\"]\n",
    "            create_file_user_info(user)\n",
    "            create_file_user_posts(api, id_login, user)\n",
    "            \n",
    "    except Exception as e:\n",
    "        error_log(acc, \"1.1\", e)\n",
    "    else:\n",
    "        log_print(f\"Account {acc} successfully processed\")\n",
    "        print(\"**********************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db1fa5c",
   "metadata": {},
   "source": [
    "## 1.2. Creating Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6d2b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_user_posts_overview(posts):\n",
    "    \n",
    "    log_print(\"Creating file user_posts_overview\")\n",
    "    \n",
    "    media_count_total = 0\n",
    "    posts_overview = {}\n",
    "    posts_overview[\"collected_at\"] = posts[\"collected_at\"]\n",
    "    posts_overview[\"num_results\"] = posts[\"num_results\"]\n",
    "    posts_overview[\"items\"] = []\n",
    "    \n",
    "    for post in posts[\"items\"]:\n",
    "        if post[\"media_type\"] == 1 or post[\"media_type\"] == 8:\n",
    "            \n",
    "            post_overview = {}\n",
    "            post_overview[\"pk\"] = post[\"pk\"]\n",
    "            post_overview[\"id\"] = post[\"id\"]\n",
    "            post_overview[\"taken_at\"] = post[\"taken_at\"]\n",
    "            post_overview[\"taken_at_year\"] = datetime.fromtimestamp(post_overview[\"taken_at\"]).year\n",
    "            \n",
    "            post_overview[\"caption_text\"] = \"\"\n",
    "            if not post[\"caption\"] is None:\n",
    "                post_overview[\"caption_text\"] = post[\"caption\"][\"text\"]\n",
    "                \n",
    "            post_overview[\"media_type\"] = post[\"media_type\"]\n",
    "            post_overview[\"images\"] = []\n",
    "            if post_overview[\"media_type\"] == 1:\n",
    "                post_overview[\"media_count\"] = 1\n",
    "                image = {}\n",
    "                image[\"pk\"] = post_overview[\"pk\"]\n",
    "                image[\"width\"] = post[\"image_versions2\"][\"candidates\"][0][\"width\"]\n",
    "                image[\"height\"] = post[\"image_versions2\"][\"candidates\"][0][\"height\"]\n",
    "                image[\"url\"] = post[\"image_versions2\"][\"candidates\"][0][\"url\"]\n",
    "                post_overview[\"images\"].append(image)\n",
    "            elif post_overview[\"media_type\"] == 8:\n",
    "                post_overview[\"media_count\"] = post[\"carousel_media_count\"]\n",
    "                for carousel_post in post[\"carousel_media\"]:\n",
    "                    image = {}\n",
    "                    image[\"pk\"] = carousel_post[\"pk\"]\n",
    "                    image[\"width\"] = carousel_post[\"image_versions2\"][\"candidates\"][0][\"width\"]\n",
    "                    image[\"height\"] = carousel_post[\"image_versions2\"][\"candidates\"][0][\"height\"]\n",
    "                    image[\"url\"] = carousel_post[\"image_versions2\"][\"candidates\"][0][\"url\"]\n",
    "                    post_overview[\"images\"].append(image)\n",
    "                    \n",
    "            media_count_total += post_overview[\"media_count\"]\n",
    "            \n",
    "            post_overview[\"location\"] = None\n",
    "            if \"location\" in post:\n",
    "                post_overview[\"location\"] = post[\"location\"]\n",
    "\n",
    "            post_overview[\"like_count\"] = post[\"like_count\"]\n",
    "            \n",
    "            post_overview[\"comments_disabled\"] = False\n",
    "            if \"comments_disabled\" in post:\n",
    "                post_overview[\"comments_disabled\"] = post[\"comments_disabled\"]\n",
    "            if post_overview[\"comments_disabled\"]:\n",
    "                post_overview[\"comment_count\"] = 0\n",
    "            else:\n",
    "                post_overview[\"comment_count\"] = post[\"comment_count\"]\n",
    "\n",
    "            post_overview[\"caption_text_length\"] = len(post_overview[\"caption_text\"])\n",
    "            hashtags = [word[1:] for word in post_overview[\"caption_text\"].split() if word[0] == '#']\n",
    "            post_overview[\"caption_hashtags_count\"] = len(hashtags)\n",
    "            post_overview[\"caption_hashtags\"] = []\n",
    "            \n",
    "            if post_overview[\"caption_hashtags_count\"] > 0:\n",
    "                post_overview[\"caption_hashtags\"] = hashtags\n",
    "            post_overview[\"timestamp_duration\"] = posts_overview[\"collected_at\"] - post_overview[\"taken_at\"]\n",
    "            post_overview[\"likes_by_duration\"] = post_overview[\"like_count\"] / post_overview[\"timestamp_duration\"]\n",
    "            post_overview[\"comments_by_duration\"] = post_overview[\"comment_count\"] / post_overview[\"timestamp_duration\"]\n",
    "            \n",
    "            posts_overview[\"items\"].append(post_overview)\n",
    "            \n",
    "    posts_overview[\"media_count_total\"] = media_count_total\n",
    "\n",
    "    with open(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"user_posts_overview.json\"), 'w+', encoding=\"utf-8\") as json_file:\n",
    "        json.dump(posts_overview, json_file, indent=4, ensure_ascii=False)\n",
    "    log_print(\"File user_posts_overview created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "45c1f7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 21:19:18 - Processing account _guasta\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account _guasta successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account joao.squinelato\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account joao.squinelato successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account analiviafr\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account analiviafr successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account nmttlbch\n",
      "2021-06-20 21:19:19 - Failed to process nmttlbch account: [Errno 2] No such file or directory: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\nmttlbch\\\\user_posts.json'\n",
      "2021-06-20 21:19:19 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account stheflacerda\n",
      "2021-06-20 21:19:19 - Failed to process stheflacerda account: [Errno 2] No such file or directory: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\stheflacerda\\\\user_posts.json'\n",
      "2021-06-20 21:19:19 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account thayfcruz\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account thayfcruz successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account mariavuzum\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account mariavuzum successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account matheuserrera\n",
      "2021-06-20 21:19:19 - Creating file user_posts_overview\n",
      "2021-06-20 21:19:19 - File user_posts_overview created\n",
      "2021-06-20 21:19:19 - Account matheuserrera successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 21:19:19 - Processing account marcos.p.andrade\n",
      "2021-06-20 21:19:19 - Failed to process marcos.p.andrade account: [Errno 2] No such file or directory: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\marcos.p.andrade\\\\user_posts.json'\n",
      "2021-06-20 21:19:19 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_accounts = get_accounts()\n",
    "for acc in list_accounts:\n",
    "    acc = str(acc).strip()\n",
    "    \n",
    "    try:\n",
    "        log_print(f\"Processing account {acc}\")\n",
    "        \n",
    "        with open(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"user_posts.json\"), encoding=\"utf-8\") as json_file:\n",
    "            posts = json.load(json_file)\n",
    "\n",
    "        create_file_user_posts_overview(posts)\n",
    "\n",
    "    except Exception as e:\n",
    "        error_log(acc, \"1.2\", e)\n",
    "    else:\n",
    "        log_print(f\"Account {acc} successfully processed\")\n",
    "        print(\"**********************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff5c8f",
   "metadata": {},
   "source": [
    "## 1.3. Downloading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "42f53157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, path):\n",
    "    resp = requests.get(url, stream=True, timeout=20)  # Open the url image, set stream to True, this will return the stream content.\n",
    "    local_file = open(path, 'wb')  # Open a local file with wb ( write binary ) permission.\n",
    "    resp.raw.decode_content = True  # Set decode_content value to True, otherwise the downloaded image file's size will be zero.\n",
    "    shutil.copyfileobj(resp.raw, local_file)  # Copy the response stream raw data to local image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d209d8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-20 22:10:55 - Processing account _guasta\n",
      "2021-06-20 22:10:55 - Failed to process _guasta account: [WinError 3] O sistema n達o pode encontrar o caminho especificado: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\_guasta\\\\images'\n",
      "2021-06-20 22:10:55 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account joao.squinelato\n",
      "2021-06-20 22:10:58 - Downloading posts pictures:\n",
      "2021-06-20 22:10:58 - 9 image(s) downloaded\n",
      "2021-06-20 22:10:58 - Account joao.squinelato successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account analiviafr\n",
      "2021-06-20 22:10:58 - Downloading posts pictures:\n",
      "2021-06-20 22:10:58 - 6 image(s) downloaded\n",
      "2021-06-20 22:10:58 - Account analiviafr successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account thayfcruz\n",
      "2021-06-20 22:10:58 - Downloading posts pictures:\n",
      "2021-06-20 22:10:58 - 15 image(s) downloaded\n",
      "2021-06-20 22:10:58 - Account thayfcruz successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account mariavuzum\n",
      "2021-06-20 22:10:58 - Downloading posts pictures:\n",
      "2021-06-20 22:10:58 - 3 image(s) downloaded\n",
      "2021-06-20 22:10:58 - Account mariavuzum successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account matheuserrera\n",
      "2021-06-20 22:10:58 - Downloading posts pictures:\n",
      "2021-06-20 22:10:58 - 0 image(s) downloaded\n",
      "2021-06-20 22:10:58 - Account matheuserrera successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:10:58 - Processing account _guasta\n",
      "2021-06-20 22:10:58 - Failed to process _guasta account: [WinError 3] O sistema n達o pode encontrar o caminho especificado: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\_guasta\\\\images'\n",
      "2021-06-20 22:10:58 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account joao.squinelato\n",
      "2021-06-20 22:11:01 - Downloading posts pictures:\n",
      "2021-06-20 22:11:01 - 9 image(s) downloaded\n",
      "2021-06-20 22:11:01 - Account joao.squinelato successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account analiviafr\n",
      "2021-06-20 22:11:01 - Downloading posts pictures:\n",
      "2021-06-20 22:11:01 - 6 image(s) downloaded\n",
      "2021-06-20 22:11:01 - Account analiviafr successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account thayfcruz\n",
      "2021-06-20 22:11:01 - Downloading posts pictures:\n",
      "2021-06-20 22:11:01 - 15 image(s) downloaded\n",
      "2021-06-20 22:11:01 - Account thayfcruz successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account mariavuzum\n",
      "2021-06-20 22:11:01 - Downloading posts pictures:\n",
      "2021-06-20 22:11:01 - 3 image(s) downloaded\n",
      "2021-06-20 22:11:01 - Account mariavuzum successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account matheuserrera\n",
      "2021-06-20 22:11:01 - Downloading posts pictures:\n",
      "2021-06-20 22:11:01 - 0 image(s) downloaded\n",
      "2021-06-20 22:11:01 - Account matheuserrera successfully processed\n",
      "**********************************************\n",
      "\n",
      "2021-06-20 22:11:01 - Processing account _guasta\n",
      "2021-06-20 22:11:01 - Failed to process _guasta account: [WinError 3] O sistema n達o pode encontrar o caminho especificado: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\_guasta\\\\images'\n",
      "2021-06-20 22:11:01 - Appending to file guastafriends_users_error.log\n",
      "**********************************************\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-aaf94d5cd8b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_FIRST_DATASET_TYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPATH_FIRST_DATASET_TYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] O sistema n達o pode encontrar o caminho especificado: 'D:\\\\IC\\\\data\\\\1-Creating_Dataset\\\\Dataset\\\\guastafriends\\\\_guasta\\\\images'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-aaf94d5cd8b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0merror_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"1.3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0magain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mlog_print\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Account {acc} successfully processed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "again = True\n",
    "while again:\n",
    "    again = False\n",
    "    list_accounts = get_accounts()\n",
    "    for acc in list_accounts:\n",
    "        acc = str(acc).strip()\n",
    "\n",
    "        try:\n",
    "            log_print(f\"Processing account {acc}\")\n",
    "            \n",
    "            if not os.path.exists(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"images\")):\n",
    "                os.mkdir(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"images\"))\n",
    "                \n",
    "            with open(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"user_posts_overview.json\"), encoding=\"utf-8\") as json_file:\n",
    "                posts_overview = json.load(json_file)\n",
    "\n",
    "            log_print(\"Downloading posts pictures:\")\n",
    "            imgs_user_downloaded = len(list(next(os.walk(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"images\")))[2])) - 1 #0 - root, 1 - dirs, 2 - files\n",
    "            if imgs_user_downloaded <= 0:\n",
    "                imgs_user_downloaded = 0\n",
    "            if imgs_user_downloaded < posts_overview['media_count_total']:\n",
    "                for post in posts_overview[\"items\"]:\n",
    "                    if not \"comments_disabled\" in post or post[\"comments_disabled\"] is False:\n",
    "                        for image in post[\"images\"]:\n",
    "                            if not os.path.exists(os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"images\", str(image[\"pk\"]) + \".jpg\")):\n",
    "                                download_image(image['url'], os.path.join(PATH_FIRST_DATASET_TYPE, acc, \"images\", f\"{image['pk']}.jpg\"))\n",
    "                                imgs_user_downloaded += 1\n",
    "                                log_print(f\"{imgs_user_downloaded}/{posts_overview['media_count_total']}\")\n",
    "                \n",
    "            log_print(f\"{imgs_user_downloaded} image(s) downloaded\")\n",
    "        except Exception as e:\n",
    "            error_log(acc, \"1.3\", e)\n",
    "            again = True\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            log_print(f\"Account {acc} successfully processed\")\n",
    "            print(\"**********************************************\\n\")\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169fc14f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
